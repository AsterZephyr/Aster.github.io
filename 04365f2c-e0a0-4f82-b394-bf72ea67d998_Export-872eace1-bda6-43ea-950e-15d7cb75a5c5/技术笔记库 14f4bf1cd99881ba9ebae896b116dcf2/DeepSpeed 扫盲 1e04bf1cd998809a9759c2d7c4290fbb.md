# DeepSpeed 扫盲

Created: 2025年4月25日 16:14
Status: 完成

**DeepSpeed 的核心并行加速技术：**

DeepSpeed 并不仅仅提供一种并行策略，而是集成并优化了多种并行技术，让它们能够协同工作。其中最核心和最著名的就是 **ZeRO (Zero Redundancy Optimizer)**。

让我们分解一下常见的并行策略以及 DeepSpeed 是如何优化它们的：

1. **数据并行 (Data Parallelism - DP)**：
    - **原理**：这是最基础的并行方式。将**整个模型复制**到每张 GPU 上。然后，将一个大的训练数据批次 (batch) 分割成小块，每张 GPU 处理一小块数据，独立计算梯度。最后，将所有 GPU 上的梯度进行平均，并用平均后的梯度更新所有 GPU 上的模型副本。
    - **优点**：实现相对简单，易于理解。
    - **缺点**：**显存瓶颈！** 每张 GPU 都需要存储完整的模型参数、梯度和优化器状态。对于非常大的模型，即使只有一份模型，单张 GPU 也可能放不下。
2. **ZeRO (Zero Redundancy Optimizer - 零冗余优化器)**：这是 DeepSpeed 的**王牌技术**，专门用来解决数据并行的显存瓶颈。
    - **核心思想**：在数据并行的基础上，不再让每张 GPU 保存所有模型状态的完整副本，而是将模型状态（参数、梯度、优化器状态）**分割 (Partition)** 到所有可用的 GPU 上。每张 GPU 只负责管理和更新它所拥有的那一部分。
    - **ZeRO 的不同阶段 (Stages)**：它有三个主要阶段，逐步增加分割的粒度，从而节省更多显存：
        - **ZeRO-Stage 1**: 只分割**优化器状态 (Optimizer States)**。模型参数和梯度在每张卡上仍然有完整副本。这是因为优化器状态（如 Adam 优化器的动量和方差）通常占用大量显存（可能是模型参数本身的两倍或更多）。
        - **ZeRO-Stage 2**: 分割**优化器状态** + **梯度 (Gradients)**。模型参数在每张卡上仍然有完整副本。在反向传播计算完梯度后，梯度会被归约 (Reduce) 到对应的 GPU 上，不再需要在所有卡上保留完整梯度。
        - **ZeRO-Stage 3**: 分割**优化器状态** + **梯度** + **模型参数 (Parameters)**。这是最彻底的分割。每张 GPU 只持有模型参数的一部分。在进行前向或反向传播计算时，如果需要用到不在这张卡上的参数，需要通过通信从持有该参数的 GPU 获取。这能最大程度地节省显存，使得能够训练的模型大小几乎可以随着 GPU 数量线性扩展。
    - **优点**：极大地降低了每张 GPU 的显存需求，使得可以在有限的硬件上训练远超单卡容量的大模型。
    - **缺点**：增加了 GPU 之间的通信开销，因为需要动态地聚合不同 GPU 上的状态。DeepSpeed 对通信进行了大量优化来降低这种开销。
3. **流水线并行 (Pipeline Parallelism - PP)**：
    - **原理**：将模型的不同**层 (Layers)** 分配到不同的 GPU 上。数据像流水线一样依次通过这些 GPU。例如，第 1-10 层在 GPU 0 上，第 11-20 层在 GPU 1 上，以此类推。
    - **优点**：降低了单张 GPU 需要存储的模型层数，从而降低显存占用。
    - **缺点**：可能存在“流水线气泡”(bubble)，即某些 GPU 可能在等待其他 GPU 完成计算而处于空闲状态，影响效率。DeepSpeed 提供了优化的调度策略来减少气泡。
4. **张量并行 (Tensor Parallelism - TP) / 模型并行 (Model Parallelism - MP)**：
    - **原理**：将模型中的单个大运算（比如一个巨大的矩阵乘法）**分割**到多个 GPU 上并行执行。例如，一个大的权重矩阵被切分成块，分布在不同的 GPU 上，每张 GPU 只计算一部分结果，最后再将结果合并。
    - **优点**：可以处理单层就非常大、单个 GPU 无法处理的情况。通常在 Transformer 模型的大型 MLP 层或 Attention 层中使用。
    - **缺点**：需要大量的 GPU 间通信。

**DeepSpeed 的优势总结：**

- **训练超大模型**：通过 ZeRO 等技术，突破单 GPU 显存限制。
- **提升训练速度**：有效利用多 GPU 的计算能力。
- **节省显存**：ZeRO 技术是其核心优势。
- **易用性**：相对于手动实现复杂的并行策略，DeepSpeed 提供了相对简单的 API 接口，只需修改少量训练脚本代码，并通过配置文件来启用和调整各种优化。通常与 PyTorch 等框架结合使用。
- **集成多种并行策略**：可以将 ZeRO、流水线并行、张量并行等结合使用，以达到最佳效果。
- **其他优化**：还包括高效的混合精度训练支持、优化的优化器（如 Fused Adam）、显存 offload（将暂时不用的模型状态转移到 CPU 内存）等。