# 如何写好prompt

Created: 2025年6月1日 01:07
Status: 完成

> https://www.bilibili.com/video/BV1ZCjgzDEwA/?spm_id_from=333.1007.tianma.1-3-3.click&vd_source=836fe27208da24d6dc88c97a9c9c3b53
> 

**开篇：Prompt 的重要性与生产环境的挑战**

- **Prompt 无处不在：** 我们平时和大型模型对话，输入的每一句话其实都是一个 Prompt。
- **生产环境的严苛要求：**
    - **高精度：** 与我们平时调试代码（可以三番五次试错）不同，线上应用的 Prompt 要求一次调用就能产生高精度的、可直接使用的结果。没有反复试错的机会，"调一次它就可能要出去，结果就要用了"。
    - **高置信度：** 目标是尽可能提升模型输出结果的置信度和准确度。
- **核心问题：** 生产环境中的 Prompt 应该是什么样子？它应该由哪些方面组成，才能达到这种高要求？

**Prompt 设计技巧概览** 

1. **单阶段技巧 (Single-Stage Techniques):**
    - **问题：** 即使 Prompt 格式都满足了，模型输出的结果（“词性”）也可能不好。
    - **目标：** 分享业界通过 Prompt 提示词技巧来提升模型遵循指令 (follow 指令) 能力的实用方法，特别是那些“放上去之后发现效果很好”的技巧。
2. **多阶段技巧 (Multi-Stage Techniques):**
    - **问题：** 很多时候，模型很难在一个阶段、一个 Prompt 内完美执行复杂任务。
    - **目标：** 如何进一步提升执行准确度？讲者会分享实用的多阶段技巧。
    - **举例：“反思”机制：**
        - 第一步：先生成一个结果。
        - 第二步：模型进行自我反思（“诶？你看你给我这个结果对不对？”）。
        - 第三步：基于反思再次生成。
    - **关键：** 哪些多阶段技巧是真正实用、精度高，并且适合放到线上跑的。
    

**为什么 Prompt Engineering 如此关键？ (深层原因与架构)**

- **典型架构：** 用户提问 -> 服务端 (Service) -> 调用大模型 API (传入 Prompt) -> 模型返回结果。
- **核心工作：** 我们如何将用户的原始查询 (query) 通过精心设计的 Prompt，转化为大模型能够理解并产生高质量（高“信趣”）结果的输入。这正是 Prompt 技巧的用武之地。
- **LLM 并非万能神话：**
    - **破除迷信：** 网上很多文章或宣传（Paper、公众号）把大模型吹得“无所不能”。
    - **现实骨感：** "真的当你去在工位去用的时候...他们没有所谓的无所不能，他其实很多事情他做不到"。模型可能“什么东西他能够都能够通一点”，但真要上线作为业务去用，会发现“还是有很多很多的问题”。
    - **Prompt 的作用：** 正因为模型本身能力没那么强，所以需要通过 Prompt 技巧等多种方式（“打各种的补丁”）让它变得更准，使其准确率达到线上工业界可用的水平。

**核心论证：不同 Prompt 带来的效果天壤之别 (岗位推荐案例详解)**

- **场景：** 岗位推荐。
- **简单 Prompt 示例:**
    - **内容：** "请帮我回答一下问题，下面的问题就是说客户真正给到你的这里面，比如说，嗯，客户当前的 query 为什么什么什么什么，然后岗位列表如下，请帮我找合适岗位，然后把岗位列表扔这..."
    - **模型输出：** 可能直接给出一个岗位名称，例如“大模型研发算法”。
    - **问题：**
        - **缺乏分析过程：** “他是没有分析，你也不知道他为什么选这个”。
        - **难以校验逻辑：** 无法判断其选择的逻辑是否正确。
        
- **精心设计的详细 Prompt 示例 (融入了类似 COT - Chain of Thought 的思维链):**
    - **第一步：赋予角色 (Persona):** "假设你是一个知识渊博的 HR 专家，你拥有很强的这种岗位推荐能力。"
    - **第二步：明确任务与分析思路 (Task Requirements & Analysis Steps):**
        1. “首先你就像你整个的分析思路，你首先要给我分析说这个用户 query 中表达的诉求，总结出用户新的诉求。”
        2. “然后分析岗位列表中每个岗位跟我这个诉求是否匹配，然后给出原因。”
        3. “最后输出合适的岗位，并按照匹配度进行这个排序。”
    - **输入：** 同样的 query 和岗位列表。
    - **模型输出 (预期)：** 会先进行分析，然后给出带有理由的推荐和排序。
    - **为什么这种方式更好？—— COT 的核心思想解读：**
        - **LLM 的本质：** 大模型是基于“Next Word Prediction”（下一个词预测）的。
        - **逻辑连贯性：** “你要是每一下一个词跟上一个词都很相关的话，那最后推论都很准确。” 如果引导模型一步一步分析，使其每一步的输出都与上文紧密相关且符合逻辑，那么最终结果的准确性就会大大提高。
        - **避免跳跃性思维：** 如果直接让模型输出选择题的 ABCD，它没有一个思考过程，很可能出错（“ABCD 很可能前面都不是那么相关”）。
        - **逐步推导的力量：** “如果说你让他是一步一步去分析，那他每出错的下一个词都跟之前的怎么样都是非常相关的。那么最后顺理成章地输出 a 或者 b 或者 c 的时候，它准确率的概率就会更高。”
        - **案例中的应用：**
            1. 先分析用户到底要干嘛 (Query)。
            2. 再分析每个岗位跟用户诉求的关系。
            3. 模型内部完成这个“类似独白的”分析过程后，就能明白哪个最好，哪个最不好，最后顺序输出。
            
    - **改进后的实际结果展示：**
        - **详细分析：** “用户希望寻找一个与大模型相关的推荐的算法岗位，强调了自己有推荐技术的背景这样...这意味着那个用户期望的岗位涉及到大模型应用，尤其是在推荐系统的上下文中...”
        - **匹配度分析：** 逐一分析岗位匹配度，例如“岗位一是怎样的较低，为什么？因为这个这样分析之后...”
        - **准确的排序列表：** 输出的排序列表更准确，如第一个是“京东物流招聘大模型算法工程师”。这比简单 Prompt 输出的“大模型研发算法”更精准，因为它结合了用户的“推荐”背景和“大模型”需求，得到了有效分析。
    - **案例小结：** 同一个问题，不同的提示词（Pump/Palm），效果完全不同。这再次印证了大模型目前尚未达到“通俗能力”（什么都能解决得很好）的阶段。
    

**Prompt 的核心组成部分 (精讲“POM”/Prompt 的构成)**

讲者详细拆解了一个优秀的 Prompt 应该包含哪些方面：

1. **任务 (Task):**
    - **定义：** 明确、确切地告诉模型要执行什么事情。
    - **重要性：** “这个是一定要有的，什么都没有，这个是一定要有的”。这是 Prompt 的基石。
    - **示例：** “请帮我判断一下用户求职的 query 与给定的岗位是否匹配。”
2. **示例 (Examples / Instances - 即 Few-shot learning):**
    - **定义：** 根据要执行的任务，给定一个或多个输入，并给出对应的期望输出。也可以没有示例 (Zero-shot)。
    - **关键点：**
        - **质量而非数量：** “这个示例其实放不是随便放的，你放一个特别简单、特别 easy 的那种，就是他一下就能说出来了，这就没有意义。”
        - **示范性：** 示例应该能够教会模型如何处理类似但更复杂的情况，而不是最简单的东西。
3. **输出格式 (Output Format):**
    - **定义：** 对模型输出内容的格式要求，例如要求输出 JSON，或者自定义的结构。
    - **核心目的：**
        - **方便下游提取：** “核心是说你在后面提取的时候的一个方便，你怎么能够把这个内容结构化地提取出来？” 如果模型每次输出格式不一，就很难解析并给用户使用，或在后续流程中继续处理。
        - **用户体验：** 即使用户直接看，格式清晰的输出也比“乱七八糟的东西，一大段文字什么结构都没有”要好得多。
    - **示例：** 输出一个 JSON 格式，包含“分析”字段和“判定的结果是否匹配”字段。
4. **角色 (Role):**
    - **定义：** 为模型设定一个身份、一个视角。
    - **示例：** “他是一个资深的 HR、商务专家”，“你是一个产品专家”，“你是一个算法专家”，“你是一个老板/学生/老师”。
    - **重要性：** “角色的定义是非常重要的啊”。
        - 有助于模型站在该角色的角度去思考问题。
        - 影响输出的语气、分析思路。
        - “网上有很多 paper 在研究说这个角色对于模型执行 follow up 的能力的一个影响”。虽然短交互可能不明显，但长交互或特定扮演场景下非常关键。
        - 若无角色设定，模型可能以它默认的、可能是“机器人”的视角来回答，不一定符合你的要求。
5. **任务要求 / 步骤 (Task Requirements / Analysis Steps):**
    - **定义：** 给定一个分析的思路，明确告诉模型“你要先做什么？再做什么？再做什么。”
    - **与 COT 的关系：** 网上常说的 COT (Chain of Thought) 的一句箴言是“请一步步分析”。但关键在于，“这个一步步，怎么个一步步？他怎么按照哪个一步步来？”
    - **为什么要固定分析思路：**
        - **一致性：** 避免模型每次处理相同任务时，内部的分析步骤不一样（“它这个一步步就会有点就是不一样”），导致结果不稳定。
        - **可调试性 (Debug)：** 如果分析思路固定，当模型出错时，更容易定位问题在哪一步，从而进行修正和优化（“就算他也出了问题，你也好 debug，你知道这里面应该加哪一步”）。
        - **可控性：** “你是能够控制，严格控制它的那个分析的这种东西的，按照你自己的设想”，所以说“你是大模型的神，就这个道理”。
        - **融入业务经验：** 这个分析思路本身就体现了你的业务经验，“你站在这个业务的角度觉得，诶，你觉得怎么做这个业务是好的？先干什么，再干什么，再干什么，它是好的”。
6. **额外信息 (Additional Information / Knowledge Base):**
    - **问题：** 大模型总有它不知道的东西，因为它的训练数据是截止到某个时间的。
    - **示例：** 讲者提到如果模型训练时 Deepseek 还没出来，它就不知道 Deepseek 是什么。当被问及时，模型可能需要去搜索。
    - **解决方案：**
        - **提供小型知识库/词典：** 在 Prompt 中直接告诉模型这些它可能不知道的信息。例如：“CV 是，比方说 computer vision，对吧？然后大模型 LMM 表示大模型”。
        - **形式：** 可以通过补充形式（如配置文件）或通过检索（RAG - Retrieval Augmented Generation，讲者提到“我们现在那个 log 也是知识库的一种，它只是一个动态的需要每次就要去检索”）。
        - **适用场景：** 对于一些场景下特定、但模型可能不知道的词汇或概念，可以作为小词典补充。如果信息量很大，建议用检索方式。
        
7. **内容格式 (Content Format - Prompt 本身的排版与强调):**
    - **重要性：** “你这个 prompt 要有什么样的格式放...你给它一个很好的格式，它能够你非常理解这个东西的时候，他也能很好地执行”。就像人阅读排版混乱的文章会很困难一样。
    - **常用方法：**
        - **Markdown：**
            - `#` 表示一级标题，`##` 表示二级标题等。
        - **划重点/强调 (Highlighting)：**
            - **重复：** “重要的事情说三遍，你可以重复三遍。”
            - **标记：** 使用星号  等特殊符号来标记重要指令或信息（“你可以给他画上这种星号，告诉他这个是重点”）。
    - **目的：** 都是为了“去增加我们模型 follow 指令的能力的”。